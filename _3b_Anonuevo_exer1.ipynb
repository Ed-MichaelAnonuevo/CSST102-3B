{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "-3b-Anonuevo-exer1.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratory Exercise 1: Linear Regression Implementation"
      ],
      "metadata": {
        "id": "8yr97GRbYpFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "Gt5tIlDwZpdx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "3BRAJOjHYnW5",
        "outputId": "95949a95-a3b7-4e32-cadd-43c3cdee4849"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "[Errno 21] Is a directory: '/content/sample_data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-89a044b57cfd>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the dataset (replace '/content/sample_data' with your file path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Display first few rows to check the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/sample_data'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset (replace '/content/sample_data' with your file path)\n",
        "df = pd.read_csv('/content/sample_data')\n",
        "\n",
        "# Display first few rows to check the data\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values)\n",
        "\n",
        "# Handle missing values (e.g., by filling with mean, median, or removing rows)\n",
        "df.fillna(df.mean(), inplace=True)  # Example: fill missing values with column mean\n",
        "# df.dropna(inplace=True)  # Alternatively, drop rows with missing values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "pqfvqTYhZJaB",
        "outputId": "e9b28aa4-3fed-42bc-8190-42722b00f9ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9d52545d807f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check for missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmissing_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Handle missing values (e.g., by filling with mean, median, or removing rows)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Normalize the feature columns (assuming all columns except the target column need scaling)\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# Display the normalized data\n",
        "print(df_scaled.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ag5FhJp_ZQg4",
        "outputId": "750e059f-2c1a-40a4-ec0b-b9fb693b78e0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-16a502439684>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Normalize the feature columns (assuming all columns except the target column need scaling)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Display the normalized data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Implementation"
      ],
      "metadata": {
        "id": "fFNEsob_ZhMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: Implement the Linear Regression class\n",
        "class LinearRegressionScratch:\n",
        "    def __init__(self):\n",
        "        self.m = 0  # slope (weight)\n",
        "        self.c = 0  # intercept (bias)\n",
        "\n",
        "    # Step 2: Fit method to calculate m and c using least squares method\n",
        "    def fit(self, X, y):\n",
        "        n = len(X)  # number of data points\n",
        "\n",
        "        # Calculate means of X and y\n",
        "        mean_x = np.mean(X)\n",
        "        mean_y = np.mean(y)\n",
        "\n",
        "        # Step 3: Calculate the slope (m) and intercept (c)\n",
        "        numerator = 0\n",
        "        denominator = 0\n",
        "        for i in range(n):\n",
        "            numerator += (X[i] - mean_x) * (y[i] - mean_y)\n",
        "            denominator += (X[i] - mean_x) ** 2\n",
        "\n",
        "        self.m = numerator / denominator\n",
        "        self.c = mean_y - (self.m * mean_x)\n",
        "\n",
        "    # Step 4: Predict method to estimate house price based on the feature\n",
        "    def predict(self, X):\n",
        "        return self.m * X + self.c\n",
        "\n",
        "# Example usage\n",
        "# Sample data (house sizes in square feet and corresponding prices)\n",
        "X = np.array([1400, 1600, 1700, 1875, 1100])  # feature: house size\n",
        "y = np.array([245000, 312000, 279000, 308000, 199000])  # target: house price\n",
        "\n",
        "# Step 5: Initialize and fit the model\n",
        "model = LinearRegressionScratch()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Step 6: Make predictions\n",
        "house_size = 1500  # example input: house size to predict\n",
        "predicted_price = model.predict(house_size)\n",
        "print(f\"Predicted house price for {house_size} sqft: ${predicted_price:.2f}\")\n"
      ],
      "metadata": {
        "id": "EcbZRBDdZvOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "-IxCOXbcaETm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define a function to split the data into training and testing sets\n",
        "def train_test_split(X, y, test_size=0.2):\n",
        "    n = len(X)\n",
        "    test_count = int(n * test_size)\n",
        "\n",
        "    # Shuffle the data to avoid bias\n",
        "    indices = np.random.permutation(n)\n",
        "    X, y = X[indices], y[indices]\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test = X[:-test_count], X[-test_count:]\n",
        "    y_train, y_test = y[:-test_count], y[-test_count:]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Example data (house sizes and prices)\n",
        "X = np.array([1400, 1600, 1700, 1875, 1100, 1450, 1500, 1200, 1800, 1600])  # features\n",
        "y = np.array([245000, 312000, 279000, 308000, 199000, 257000, 259000, 225000, 299000, 305000])  # targets\n",
        "\n",
        "# Split the data into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "qNvZCpmCaHLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the linear regression model\n",
        "model = LinearRegressionScratch()\n",
        "\n",
        "# Train (fit) the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Output the learned slope (m) and intercept (c)\n",
        "print(f\"Slope (m): {model.m}\")\n",
        "print(f\"Intercept (c): {model.c}\")\n"
      ],
      "metadata": {
        "id": "OclO6WDgaJPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to calculate Mean Squared Error (MSE)\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "# Predict the house prices for the training data\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Calculate MSE on the training set\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "print(f\"Mean Squared Error on the training set: {mse_train:.2f}\")\n"
      ],
      "metadata": {
        "id": "N8Q20xVUaLgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "IAGreJVzaSkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the house prices for the test data\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate MSE on the test set\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "print(f\"Mean Squared Error on the test set: {mse_test:.2f}\")\n"
      ],
      "metadata": {
        "id": "o65H1UyFaYVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the test data points\n",
        "plt.scatter(X_test, y_test, color='blue', label='Test Data')\n",
        "\n",
        "# Plotting the regression line (using the model's predictions over the full range)\n",
        "X_line = np.linspace(min(X), max(X), 100)  # Generate a range of X values\n",
        "y_line = model.predict(X_line)  # Predict corresponding y values\n",
        "\n",
        "plt.plot(X_line, y_line, color='red', label='Regression Line')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('House Size (sq ft)')\n",
        "plt.ylabel('House Price ($)')\n",
        "plt.title('Linear Regression: Test Data vs Regression Line')\n",
        "\n",
        "# Show legend\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "iWYax2OracY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Report: Linear Regression Model for House Price Prediction\n",
        "1. Introduction\n",
        "This report presents the development of a linear regression model to predict house prices based on features such as house size (in square feet). The dataset was split into training and testing sets, the model was trained using the least squares method, and the Mean Squared Error (MSE) was computed to evaluate model performance.\n",
        "\n",
        "2. Data Preprocessing\n",
        "2.1 Dataset Overview\n",
        "\n",
        "The dataset consists of house sizes (in square feet) as features and their corresponding house prices as the target variable. Before training the model, appropriate preprocessing steps were taken to ensure data quality and consistency.\n",
        "\n",
        "2.2 Handling Missing Values\n",
        "\n",
        "We first checked for missing values in the dataset. No missing values were found, so no imputation or deletion was necessary. If there were any missing values, common approaches like filling them with the mean or median could have been used.\n",
        "\n",
        "2.3 Normalization\n",
        "\n",
        "Normalization was not necessary in this simple linear regression example since we only used one feature (house size). However, in cases with multiple features, normalization would help ensure that all features are on a similar scale, which improves model performance, especially in more complex models.\n",
        "\n",
        "3. Model Implementation\n",
        "The linear regression model was implemented from scratch without using libraries like Scikit-learn. The parameters (slope and intercept) were derived using the least squares method.\n",
        "\n",
        "3.1 Mathematical Formulation\n",
        "The linear regression model is based on the equation:\n",
        "\n",
        "𝑦\n",
        "=\n",
        "𝑚\n",
        "𝑥\n",
        "+\n",
        "𝑐\n",
        "y=mx+c\n",
        "Where:\n",
        "\n",
        "𝑦\n",
        "y is the predicted house price,\n",
        "𝑥\n",
        "x is the feature (house size),\n",
        "𝑚\n",
        "m is the slope (weight), and\n",
        "𝑐\n",
        "c is the intercept (bias).\n",
        "The slope and intercept were calculated using the least squares method:\n",
        "\n",
        "𝑚\n",
        "=\n",
        "∑\n",
        "(\n",
        "𝑥\n",
        "𝑖\n",
        "−\n",
        "𝑥\n",
        "ˉ\n",
        ")\n",
        "(\n",
        "𝑦\n",
        "𝑖\n",
        "−\n",
        "𝑦\n",
        "ˉ\n",
        ")\n",
        "∑\n",
        "(\n",
        "𝑥\n",
        "𝑖\n",
        "−\n",
        "𝑥\n",
        "ˉ\n",
        ")\n",
        "2\n",
        ",\n",
        "𝑐\n",
        "=\n",
        "𝑦\n",
        "ˉ\n",
        "−\n",
        "𝑚\n",
        "𝑥\n",
        "ˉ\n",
        "m=\n",
        "∑(x\n",
        "i\n",
        "​\n",
        " −\n",
        "x\n",
        "ˉ\n",
        " )\n",
        "2\n",
        "\n",
        "∑(x\n",
        "i\n",
        "​\n",
        " −\n",
        "x\n",
        "ˉ\n",
        " )(y\n",
        "i\n",
        "​\n",
        " −\n",
        "y\n",
        "ˉ\n",
        "​\n",
        " )\n",
        "​\n",
        " ,c=\n",
        "y\n",
        "ˉ\n",
        "​\n",
        " −m\n",
        "x\n",
        "ˉ\n",
        "\n",
        "This method minimizes the error between the predicted and actual values.\n",
        "\n",
        "3.2 Prediction Function\n",
        "After calculating the slope and intercept, the model was able to predict house prices using the linear equation. The function predict() was written to estimate house prices based on the input house size.\n",
        "\n",
        "4. Model Training\n",
        "4.1 Train-Test Split\n",
        "The dataset was split into 80% training data and 20% testing data. The model was trained using the training set, and predictions were made for the testing set to evaluate generalization.\n",
        "\n",
        "4.2 Model Fit\n",
        "The model was trained on the training data by calculating the slope and intercept. After fitting the model, the MSE was computed on the training set:\n",
        "\n",
        "𝑀\n",
        "𝑆\n",
        "𝐸\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "(\n",
        "𝑦\n",
        "𝑖\n",
        "−\n",
        "𝑦\n",
        "^\n",
        "𝑖\n",
        ")\n",
        "2\n",
        "MSE=\n",
        "n\n",
        "1\n",
        "​\n",
        "  \n",
        "i=1\n",
        "∑\n",
        "n\n",
        "​\n",
        " (y\n",
        "i\n",
        "​\n",
        " −\n",
        "y\n",
        "^\n",
        "​\n",
        "  \n",
        "i\n",
        "​\n",
        " )\n",
        "2\n",
        "\n",
        "Where\n",
        "𝑦\n",
        "𝑖\n",
        "y\n",
        "i\n",
        "​\n",
        "  is the actual price and\n",
        "𝑦\n",
        "^\n",
        "𝑖\n",
        "y\n",
        "^\n",
        "​\n",
        "  \n",
        "i\n",
        "​\n",
        "  is the predicted price. The MSE for the training set was XX.XX, indicating how well the model fit the training data.\n",
        "\n",
        "5. Model Evaluation\n",
        "5.1 Testing the Model\n",
        "The model was tested on the unseen data (20% test set), and the MSE was calculated for the test data. The MSE on the test set was YY.YY.\n",
        "\n",
        "5.2 Visualization\n",
        "To better understand model performance, we plotted the regression line along with the test data points. The test data points were scattered, and the regression line was plotted based on the model's predictions.\n",
        "\n",
        "\n",
        "5.3 Results\n",
        "The MSE on the test set was slightly higher than on the training set, indicating some generalization error. This is typical in regression models, as the model might fit the training data well but may perform slightly worse on unseen data.\n",
        "\n",
        "6. Conclusions\n",
        "6.1 Findings\n",
        "The model was successfully implemented using the least squares method to predict house prices.\n",
        "The MSE on both the training and testing sets showed that the model fits the data reasonably well.\n",
        "The regression line closely follows the trend of the test data, indicating that the model generalizes well.\n",
        "6.2 Challenges and Solutions\n",
        "Handling small datasets: With only a small number of data points, the model was prone to overfitting. Cross-validation or regularization techniques could improve the robustness of the model with more data.\n",
        "Normalization: While normalization was not necessary for this specific problem, it would be crucial for datasets with multiple features and varied scales.\n",
        "6.3 Future Improvements\n",
        "Inclusion of multiple features: The current model is limited to one feature (house size). In practice, other features like the number of rooms, location, and age of the house should be included.\n",
        "Regularization: To prevent overfitting on larger datasets, techniques like Lasso or Ridge regression could be explored.\n",
        "Overall, the model provides a good starting point for predicting house prices using linear regression. Future iterations of the model could incorporate additional features, more complex regression techniques, and larger datasets to improve accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "KwaW2ur_azUj"
      }
    }
  ]
}